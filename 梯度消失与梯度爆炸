梯度消失和梯度爆炸的本质都是由于反向传播的链式效应；由于网络层数太深，网络全值更新不稳定导致的；也有可能是激活函数选取不正确导致（sigmoid函数）

梯度消失指的是越靠近input的导数越小，越靠近output的导数越大；这种情况会导致当浅层权值还是random时，深层权值已经converge，导致了local
minimum的情况；出现这种情况的原因是，浅层的导数是深层导数相乘的结果，当深层导数均为小于1的数值时，传到浅层导数已经几乎为0；尤其的，一般|w|<1，若使用sigmoid 激活函数时，L针对w1的导数是alpha(L)/alpha(w1) = sigma'(z3) * w3 *sigma'(z2) * w2 * sigma'(z1) * w1 ；sigmoid函数的导数最大值为|1/4|,导致每层导数都小于1

梯度爆炸则相反，当深层的导数大于1，传导到浅层导数将是一个很大的值


参考：https://zhuanlan.zhihu.com/p/25631496
